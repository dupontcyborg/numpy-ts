---
title: "Image Processing"
description: "Represent images as arrays, slice regions of interest, apply element-wise transforms, transpose channels, and build convolution filters."
---

import { Playground } from '/snippets/Playground.jsx'

Images are naturally represented as multi-dimensional arrays. A grayscale image is a 2-D array of pixel intensities, while a color image is a 3-D array with a channel dimension. numpy-ts provides the array operations needed for common image processing tasks.

## Representing images as 2D/3D arrays

<Playground
  code={String.raw`// Grayscale image: 2-D array of shape [height, width]
// Values typically in [0, 255] for uint8 or [0.0, 1.0] for float
const grayscale = np.zeros([480, 640], 'uint8');
console.log('Grayscale shape:', grayscale.shape, '\n');

// RGB image: 3-D array of shape [height, width, channels]
const rgb = np.zeros([480, 640, 3], 'uint8');
console.log('RGB shape:', rgb.shape, '\n');

// Create a synthetic test image: horizontal gradient
const width = 256;
const height = 256;
const row = np.arange(0, width, 1, 'uint8');
const gradient = np.tile(row, [height, 1]);
console.log('Gradient shape:', gradient.shape, '\n');

// Create a checkerboard pattern
const blockSize = 32;
const board = np.zeros([256, 256], 'uint8');

// Fill using numpy operations
const rowIdx = np.arange(256).reshape([256, 1]).floor_divide(blockSize);
const colIdx = np.arange(256).reshape([1, 256]).floor_divide(blockSize);
const checker = np.mod(np.add(rowIdx, colIdx), 2);
console.log('Checkerboard shape:', checker.shape, '\n');`}
  showImportHeader={true}
  showCopyButton={true}
/>

---

## Slicing regions of interest

Extract sub-images using NumPy-style slicing.

<Playground
  code={String.raw`// Simulated 480x640 RGB image
const image = np.random.randint(0, 256, [480, 640, 3], 'uint8');

// Extract a 100x100 region starting at (50, 100)
const roi = image.slice('50:150', '100:200', ':');
console.log('ROI shape:', roi.shape, '\n');

// Extract a single channel (e.g., red channel)
const red = image.slice(':', ':', '0');
console.log('Red channel shape:', red.shape, '\n');

// Extract the center 200x200 patch
const cy = 240, cx = 320, halfSize = 100;
const y = (cy - halfSize) + ':' + (cy + halfSize);
const x = (cx - halfSize) + ':' + (cx + halfSize);
const center = image.slice(y, x, ':')
console.log('Center patch shape:', center.shape, '\n');

// Downsample by taking every other pixel
const downsampled = image.slice('::2', '::2', ':');
console.log('Downsampled shape:', downsampled.shape, '\n');

// Flip the image vertically (reverse rows)
const flipped = np.flip(image, 0);
console.log('Flipped shape:', flipped.shape, '\n');

// Rotate 90 degrees
const rotated = np.rot90(image);
console.log('Rotated shape:', rotated.shape, '\n');`}
  showImportHeader={true}
  showCopyButton={true}
/>

---

## Element-wise transforms: brightness and contrast

Adjust pixel values using vectorized arithmetic -- no loops required.

<Playground
  code={[
    "// Work in float for precision, then convert back to uint8",
    "const image = np.random.randint(0, 256, [256, 256, 3])",
    "  .divide(255.0);",
    "",
    "// Print a tiny patch so we can see actual values",
    "console.log('Original patch [0:2, 0:5, :]:\\n' + image.slice('0:2', '0:5', ':').toString(), '\\n');",
    "console.log('Original range (min/max):', np.amin(image), '-', np.amax(image), '\\n');",
    "",
    "// Brightness adjustment: add a constant",
    "const brightnessOffset = 0.2;",
    "const brighter = np.clip(np.add(image, brightnessOffset), 0, 1);",
    "const darker = np.clip(np.subtract(image, brightnessOffset), 0, 1);",
    "",
    "console.log('Brighter patch [0:2, 0:5, :]:\\n' + brighter.slice('0:2', '0:5', ':').toString(), '\\n');",
    "console.log('Darker patch [0:2, 0:5, :]:\\n' + darker.slice('0:2', '0:5', ':').toString(), '\\n');",
    "",
    "// Contrast adjustment: scale around the mean",
    "const mean = np.mean(image);",
    "const contrastFactor = 1.5;",
    "const highContrast = image",
    "  .subtract(mean)",
    "  .multiply(contrastFactor)",
    "  .add(mean)",
    "  .clip(0, 1);",
    "",
    "console.log('High-contrast patch [0:2, 0:5, :]:\\n' + highContrast.slice('0:2', '0:5', ':').toString(), '\\n');",
    "",
    "// Gamma correction: raise to a power",
    "const gamma = 2.2;",
    "const gammaCorrected = np.power(image, 1 / gamma);",
    "console.log('Gamma-corrected patch [0:2, 0:5, :]:\\n' + gammaCorrected.slice('0:2', '0:5', ':').toString(), '\\n');",
    "",
    "// Invert the image",
    "const inverted = image",
    "  .multiply(-1.0)",
    "  .add(1.0);",
    "console.log('Inverted patch [0:2, 0:5, :]:\\n' + inverted.slice('0:2', '0:5', ':').toString(), '\\n');",
    "",
    "// Convert back to uint8 for display",
    "const result = np.multiply(brighter, 255).astype('uint8');",
    "console.log('Result dtype:', result.dtype);",
    "console.log('Result range (min/max):', np.amin(result), '-', np.amax(result), '\\n');",
    "console.log('Result patch [0:2, 0:5, :]:\\n' + result.slice('0:2', '0:5', ':').toString(), '\\n');",
  ].join("\n")}
  showImportHeader={true}
  showCopyButton={true}
/>

---

## Reshaping and transposing for channel reordering

Different frameworks expect different axis orderings. Use `transpose` and `reshape` to convert between them.

<Playground
  code={String.raw`// HWC format (height, width, channels) -- common in image APIs
const hwc = np.random.randint(0, 256, [224, 224, 3], 'uint8');
console.log('HWC shape:', hwc.shape, '\n');

// Convert to CHW format (channels, height, width) -- used by ML frameworks
const chw = np.transpose(hwc, [2, 0, 1]);
console.log('CHW shape:', chw.shape, '\n');

// Convert back to HWC
const backToHwc = np.transpose(chw, [1, 2, 0]);
console.log('Back to HWC:', backToHwc.shape, '\n');

// Add a batch dimension (NCHW for batched inference)
const batch = np.expand_dims(chw, 0);
console.log('NCHW batch shape:', batch.shape, '\n');

// Stack multiple images into a batch
const img1 = np.random.randint(0, 256, [3, 224, 224], 'uint8');
const img2 = np.random.randint(0, 256, [3, 224, 224], 'uint8');
const img3 = np.random.randint(0, 256, [3, 224, 224], 'uint8');
const batchOf3 = np.stack([img1, img2, img3]);
console.log('Batch of 3:', batchOf3.shape, '\n');

// Extract a single channel and squeeze
const greenChannel = chw.slice('1:2', ':', ':');  // shape [1, 224, 224]
const greenSqueezed = np.squeeze(greenChannel, 0); // shape [224, 224]
console.log('Green channel:', greenSqueezed.shape, '\n');`}
  showImportHeader={true}
  showCopyButton={true}
/>

---

## Simple convolution filter

Apply spatial filters to images using convolution. For a 2-D image, convolve each row and column separately using 1-D convolution, or build a simple approach using element-wise operations.

<Playground
  code={[
    "// Create a simple 8x8 grayscale 'image'",
    "const image = np.array([",
    "  [0, 0, 0, 0, 0, 0, 0, 0],",
    "  [0, 0, 0, 1, 1, 0, 0, 0],",
    "  [0, 0, 1, 1, 1, 1, 0, 0],",
    "  [0, 1, 1, 1, 1, 1, 1, 0],",
    "  [0, 1, 1, 1, 1, 1, 1, 0],",
    "  [0, 0, 1, 1, 1, 1, 0, 0],",
    "  [0, 0, 0, 1, 1, 0, 0, 0],",
    "  [0, 0, 0, 0, 0, 0, 0, 0],",
    "]);",
    "",
    "const smoothKernel = np.array([1 / 3, 1 / 3, 1 / 3]);",
    "const rows = image.shape[0];",
    "",
    "// Apply row-by-row convolution",
    "const smoothedRows = [];",
    "for (let i = 0; i < rows; i++) {",
    "  const row = image.row(i);",
    "  smoothedRows.push(np.convolve(row, smoothKernel, 'same'));",
    "}",
    "const rowSmoothed = np.stack(smoothedRows);",
    "",
    "// Then smooth columns by transposing, convolving rows, and transposing back",
    "const cols = rowSmoothed.shape[1];",
    "const smoothedCols = [];",
    "for (let j = 0; j < cols; j++) {",
    "  const col = image.col(j);",
    "  smoothedCols.push(np.convolve(col, smoothKernel, 'same'));",
    "}",
    "const fullySmoothed = np.transpose(np.stack(smoothedCols));",
    "",
    "console.log('Smoothed image:', '\\n');",
    "console.log(fullySmoothed.toString(), '\\n');",
  ].join("\n")}
  showImportHeader={true}
  showCopyButton={true}
/>

<Tip>
For large-scale 2-D convolution, consider using the FFT approach: pad the image and kernel to the same size, multiply their FFTs, and inverse-transform the result. This runs in O(N log N) instead of O(N * K).
</Tip>